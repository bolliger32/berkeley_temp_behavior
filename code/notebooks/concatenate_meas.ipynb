{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create session-level measurements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook concatenates all of the measurements collected on various dates into one csv per site. The metrics consist of the following measures, with one summary statistic per session-treatment group:\n",
    "\n",
    "- indoor air temperature (mean, std dev, quartiles)\n",
    "- indoor relative humidity (mean, std dev, quartiles)\n",
    "- outdoor air temperature, avg/min/max over the date of each session.\n",
    "- outdoor relative humidity, avg/min/max over the date of each session.\n",
    "\n",
    "TO-DO:\n",
    "\n",
    "add the following:\n",
    "- participant level mean T and RH, averaged over duration of session.\n",
    "- CO2 in control and tx\n",
    "- operative temp in control and tx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../scripts/')\n",
    "from utilities import *\n",
    "\n",
    "import pandas as pd\n",
    "from os.path import join\n",
    "\n",
    "import pickle\n",
    "import pdb\n",
    "\n",
    "idx = pd.IndexSlice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_dir = '/Users/ianbolliger/Dropbox/Temperature & Behavior/Experiments'\n",
    "s = Settings(home_dir)\n",
    "\n",
    "save_fpath_berk = join(s.berk.home_dir,'session_level_environmental_data.csv')\n",
    "save_fpath_bus = join(s.bus.home_dir,'session_level_environmental_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_session_level_indoor_vals(dfs, timing_df, site_settings):\n",
    "    out_df = pd.DataFrame()\n",
    "    idx = pd.IndexSlice\n",
    "\n",
    "    for grp_ix,grp in enumerate(['control','treatment']):\n",
    "        grp_df = timing_df[timing_df['Treatment group']==grp_ix]\n",
    "\n",
    "        # one dataframe for each sensor location\n",
    "        loc_dfs = []\n",
    "        for loc in site_settings.sens_locs:\n",
    "            tmp_df = dfs[grp][loc].reset_index()\n",
    "            tmp_df['sess'] = pd.cut(tmp_df['time'],bins=grp_df.index)\n",
    "            grouped = tmp_df.groupby('sess').describe()\n",
    "\n",
    "            # drop pilot sessions where we don't have room-level sensors (only individual)\n",
    "            grouped = grouped[grouped.loc[:,idx[:,'count']].sum(axis=1)!=0]\n",
    "\n",
    "            # don't need # of measurements taken in session\n",
    "            grouped = grouped.drop(columns='count',level=1)\n",
    "\n",
    "            loc_dfs.append(grouped)\n",
    "\n",
    "        # estimate average values for sessions where only one sensor recording\n",
    "        # then average the sensors for each session\n",
    "        sesh_vals = average_two_sensors(loc_dfs)\n",
    "\n",
    "        # clarify that these are indoor temps and RH vals\n",
    "        def renamer(x):\n",
    "            if x == 'one_sensor_only':\n",
    "                return 'one_sensor_only_in'\n",
    "            return x.split('_')[0] + '_in_' + x.split('_')[1]\n",
    "        sesh_vals = sesh_vals.rename(renamer,axis=1)\n",
    "        \n",
    "        sesh_vals = sesh_vals.join(grp_df,how='inner')\n",
    "        out_df = out_df.append(sesh_vals)\n",
    "\n",
    "    # format nicely\n",
    "    out_df = out_df.rename(columns={'Date':'date','Session in day':'session','Treatment group':'treatment'})\n",
    "    out_df = out_df.set_index(['date','session','treatment'])\n",
    "    out_df = out_df.drop(columns=['start_time','end_time'])\n",
    "    out_df.columns = [c.rstrip('%') for c in out_df.columns]\n",
    "    out_df = out_df.sort_index()\n",
    "    out_df = out_df[out_df.notnull().any(axis=1)]\n",
    "    \n",
    "    return out_df\n",
    "\n",
    "def average_two_sensors(loc_dfs):\n",
    "    loc_dfs = bias_correct_one_sensor(loc_dfs)\n",
    "    sesh_vals = (loc_dfs[0] + loc_dfs[1]) / 2\n",
    "    sesh_vals['one_sensor_only'] = pd.DataFrame([loc_dfs[0]['one_sensor_only'],\n",
    "                                                 loc_dfs[1]['one_sensor_only']]).max()\n",
    "    return sesh_vals\n",
    "\n",
    "def bias_correct_one_sensor(loc_dfs):\n",
    "    \"\"\"When only one sensor in a room, bias correct that sensor to estimate\n",
    "    the average of the two sensors for that session.\"\"\"\n",
    "    # find mean difference in sensor\n",
    "    mean_diff = (loc_dfs[1] - loc_dfs[0]).mean()\n",
    "    # flatten index\n",
    "    mean_diff.index = [(i[0]+'_'+i[1]).rstrip('_') for i in mean_diff.index.values]\n",
    "\n",
    "    # get df with all sessions where at least one sensor was working\n",
    "    all_locs = loc_dfs[1].join(loc_dfs[0],rsuffix='0',lsuffix='1')\n",
    "\n",
    "    # adjust for one-sensor-only times\n",
    "    # workaround b/c reindex fails with intervalIndex (bug)\n",
    "    for i in [0,1]:\n",
    "        loc_dfs[i] = all_locs.loc[:,idx[[k for k in all_locs.columns.levels[0] if k[-1] == str(i)],:]]\n",
    "        \n",
    "        # convert to single-level index\n",
    "        loc_dfs[i] = loc_dfs[i].rename(lambda x: x[:-1],axis=1,level=0)\n",
    "        loc_dfs[i].columns = [(j[0]+'_'+j[1]).rstrip('_') for j in loc_dfs[i].columns.values]\n",
    "        \n",
    "        # mark where we did bias correction\n",
    "        loc_dfs[i]['one_sensor_only'] = loc_dfs[i].isnull().any(axis=1)\n",
    "\n",
    "    loc_dfs[1].iloc[:,:-1] = loc_dfs[1].iloc[:,:-1].where(~loc_dfs[1]['one_sensor_only'],loc_dfs[0].iloc[:,:-1]+mean_diff)\n",
    "    loc_dfs[0].iloc[:,:-1] = loc_dfs[0].iloc[:,:-1].where(~loc_dfs[0]['one_sensor_only'],loc_dfs[1].iloc[:,:-1]-mean_diff)\n",
    "    \n",
    "    return loc_dfs\n",
    "\n",
    "def add_outdoor_vals(output_df, dfs_outdoor, timing_df):\n",
    "    res = output_df.copy()\n",
    "    for i in ['min','mean','max']:\n",
    "        to_join = dfs_outdoor[i].copy()\n",
    "        to_join.index = pd.to_datetime(to_join.index)\n",
    "        to_join = timing_df.join(to_join,on='Date',how='inner').drop_duplicates(\n",
    "                ).set_index(\n",
    "                ['Date', 'Session in day', 'Treatment group']).loc[:,['T','RH']]\n",
    "        to_join.columns = [r+'_out_daily'+i for r in to_join.columns]\n",
    "        to_join.index.names = res.index.names\n",
    "        res = res.join(to_join,how='outer')\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Berkeley"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ianbolliger/anaconda/envs/cooking_people/lib/python3.6/site-packages/pandas/core/indexing.py:357: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/Users/ianbolliger/anaconda/envs/cooking_people/lib/python3.6/site-packages/pandas/core/indexing.py:537: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "timing_df_berk = get_timing_df_berk(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ianbolliger/anaconda/envs/cooking_people/lib/python3.6/site-packages/pandas/core/indexing.py:357: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/Users/ianbolliger/anaconda/envs/cooking_people/lib/python3.6/site-packages/pandas/core/indexing.py:537: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "# load dataframes \n",
    "dfs_berk = load_vals_berkeley(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indoor temp and RH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ianbolliger/anaconda/envs/cooking_people/lib/python3.6/site-packages/pandas/core/computation/expressions.py:179: UserWarning: evaluating in Python space because the '+' operator is not supported by numexpr for the bool dtype, use '|' instead\n",
      "  .format(op=op_str, alt_op=unsupported[op_str]))\n"
     ]
    }
   ],
   "source": [
    "idx = pd.IndexSlice\n",
    "out_df_berk = calc_session_level_indoor_vals(dfs_berk['indoor'], timing_df_berk, s.berk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outdoor temp/rh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df_berk = add_outdoor_vals(out_df_berk, dfs_berk['outdoor'], timing_df_berk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df_berk.to_csv(save_fpath_berk,float_format='%.2f')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Busara"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading control room data...\n",
      "Downloading 20171017...\n",
      "Downloading far sensor...\n",
      "Downloading near sensor...\n",
      "Downloading 20171019...\n",
      "Downloading far sensor...\n",
      "Downloading near sensor...\n",
      "Downloading 20171101...\n",
      "Downloading far sensor...\n",
      "Downloading near sensor...\n",
      "Downloading 20171102...\n",
      "Downloading far sensor...\n",
      "Downloading near sensor...\n",
      "Downloading 20171103...\n",
      "Downloading far sensor...\n",
      "Downloading near sensor...\n",
      "Downloading 20171106...\n",
      "Downloading far sensor...\n",
      "Downloading near sensor...\n",
      "Downloading 20171107...\n",
      "Downloading far sensor...\n",
      "Downloading near sensor...\n",
      "Downloading 20171108...\n",
      "Downloading far sensor...\n",
      "Downloading near sensor...\n",
      "Downloading 20171109...\n",
      "Downloading far sensor...\n",
      "Downloading near sensor...\n",
      "Downloading 20171110...\n",
      "Downloading far sensor...\n",
      "Downloading near sensor...\n",
      "Downloading 20171113...\n",
      "Downloading far sensor...\n",
      "Downloading near sensor...\n",
      "Downloading 20171114...\n",
      "Downloading far sensor...\n",
      "Downloading near sensor...\n",
      "Downloading 20171116...\n",
      "Downloading far sensor...\n",
      "Downloading near sensor...\n",
      "Downloading 20171117...\n",
      "Downloading far sensor...\n",
      "Downloading near sensor...\n",
      "Downloading 20171121...\n",
      "Downloading far sensor...\n",
      "Downloading near sensor...\n",
      "Downloading 20171122...\n",
      "Downloading far sensor...\n",
      "Downloading near sensor...\n",
      "Downloading 20171123...\n",
      "Downloading far sensor...\n",
      "Downloading near sensor...\n",
      "Downloading 20171124...\n",
      "Downloading far sensor...\n",
      "Downloading near sensor...\n",
      "Downloading 20171127...\n",
      "Downloading far sensor...\n",
      "Downloading near sensor...\n",
      "Downloading 20171129...\n",
      "Downloading far sensor...\n",
      "Downloading near sensor...\n",
      "Downloading 20171130...\n",
      "Downloading far sensor...\n",
      "Downloading near sensor...\n",
      "Downloading 20171201...\n",
      "Downloading far sensor...\n",
      "Downloading near sensor...\n",
      "Downloading 20171204...\n",
      "Downloading far sensor...\n",
      "Downloading near sensor...\n",
      "Downloading 20171205...\n",
      "Downloading far sensor...\n",
      "Downloading near sensor...\n",
      "Downloading 20171206...\n",
      "Downloading far sensor...\n",
      "Downloading near sensor...\n",
      "Downloading 20171207...\n",
      "Downloading far sensor...\n",
      "Downloading near sensor...\n",
      "Downloading 20171208...\n",
      "Downloading far sensor...\n",
      "Downloading near sensor...\n",
      "Downloading 20171211...\n",
      "Downloading far sensor...\n",
      "Downloading near sensor...\n",
      "Downloading 20171212...\n",
      "Downloading far sensor...\n",
      "Downloading near sensor...\n",
      "Downloading 20171213...\n",
      "Downloading far sensor...\n",
      "Downloading near sensor...\n",
      "Downloading 20171214...\n",
      "Downloading far sensor...\n",
      "Downloading near sensor...\n",
      "Downloading 20180123...\n",
      "Downloading far sensor...\n",
      "Downloading near sensor...\n",
      "Downloading 20180124...\n",
      "Downloading far sensor...\n",
      "Downloading near sensor...\n",
      "Downloading 20180125...\n",
      "Downloading far sensor...\n",
      "Downloading near sensor...\n",
      "Downloading 20180205...\n",
      "Downloading far sensor...\n",
      "Downloading near sensor...\n",
      "Downloading 20180206...\n",
      "Downloading far sensor...\n",
      "Downloading near sensor...\n",
      "Downloading 20180208...\n",
      "Downloading far sensor...\n",
      "Downloading near sensor...\n",
      "Downloading treatment room data...\n",
      "Downloading 20171017...\n",
      "Downloading far sensor...\n",
      "Downloading near sensor...\n",
      "Downloading 20171019...\n",
      "Downloading far sensor...\n",
      "Downloading near sensor...\n",
      "Downloading 20171101...\n",
      "Downloading far sensor...\n",
      "Downloading near sensor...\n",
      "Downloading 20171102...\n",
      "Downloading far sensor...\n",
      "Downloading near sensor...\n",
      "Downloading 20171103...\n",
      "Downloading far sensor...\n",
      "Downloading near sensor...\n",
      "Downloading 20171106...\n",
      "Downloading far sensor...\n",
      "Downloading near sensor...\n",
      "Downloading 20171107...\n",
      "Downloading far sensor...\n",
      "Downloading near sensor...\n",
      "Downloading 20171108...\n",
      "Downloading far sensor...\n",
      "Downloading near sensor...\n",
      "Downloading 20171109...\n",
      "Downloading far sensor...\n",
      "Downloading near sensor...\n",
      "Downloading 20171110...\n",
      "Downloading far sensor...\n",
      "Downloading near sensor...\n",
      "Downloading 20171113...\n",
      "Downloading far sensor...\n",
      "Downloading near sensor...\n",
      "Downloading 20171114...\n",
      "Downloading far sensor...\n",
      "Downloading near sensor...\n",
      "Downloading 20171116...\n",
      "Downloading far sensor...\n",
      "Downloading near sensor...\n",
      "Downloading 20171117...\n",
      "Downloading far sensor...\n",
      "Downloading near sensor...\n",
      "Downloading 20171121...\n",
      "Downloading far sensor...\n",
      "Downloading near sensor...\n",
      "Downloading 20171122...\n",
      "Downloading far sensor...\n",
      "Downloading near sensor...\n",
      "Downloading 20171123...\n",
      "Downloading far sensor...\n",
      "Downloading near sensor...\n",
      "Downloading 20171124...\n",
      "Downloading far sensor...\n",
      "Downloading near sensor...\n",
      "Downloading 20171127...\n",
      "Downloading far sensor...\n",
      "Downloading near sensor...\n",
      "Downloading 20171129...\n",
      "Downloading far sensor...\n",
      "Downloading near sensor...\n",
      "Downloading 20171130...\n",
      "Downloading far sensor...\n",
      "Downloading near sensor...\n",
      "Downloading 20171201...\n",
      "Downloading far sensor...\n",
      "Downloading near sensor...\n",
      "Downloading 20171204...\n",
      "Downloading far sensor...\n",
      "Downloading near sensor...\n",
      "Downloading 20171205...\n",
      "Downloading far sensor...\n",
      "Downloading near sensor...\n",
      "Downloading 20171206...\n",
      "Downloading far sensor...\n",
      "Downloading near sensor...\n",
      "Downloading 20171207...\n",
      "Downloading far sensor...\n",
      "Downloading near sensor...\n",
      "Downloading 20171208...\n",
      "Downloading far sensor...\n",
      "Downloading near sensor...\n",
      "Downloading 20171211...\n",
      "Downloading far sensor...\n",
      "Downloading near sensor...\n",
      "Downloading 20171212...\n",
      "Downloading far sensor...\n",
      "Downloading near sensor...\n",
      "Downloading 20171213...\n",
      "Downloading far sensor...\n",
      "Downloading near sensor...\n",
      "Downloading 20171214...\n",
      "Downloading far sensor...\n",
      "Downloading near sensor...\n",
      "Downloading 20180123...\n",
      "Downloading far sensor...\n",
      "Downloading near sensor...\n",
      "Downloading 20180124...\n",
      "Downloading far sensor...\n",
      "Downloading near sensor...\n",
      "Downloading 20180125...\n",
      "Downloading far sensor...\n",
      "Downloading near sensor...\n",
      "Downloading 20180205...\n",
      "Downloading far sensor...\n",
      "Downloading near sensor...\n",
      "Downloading 20180206...\n",
      "Downloading far sensor...\n",
      "Downloading near sensor...\n",
      "Downloading 20180208...\n",
      "Downloading far sensor...\n",
      "Downloading near sensor...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../scripts/utilities.py:152: UserWarning: Missing file: 20180208_Temp_WN.*csv\n",
      "  warnings.warn('Missing file: {}'.format(fname))\n",
      "/Users/ianbolliger/anaconda/envs/cooking_people/lib/python3.6/site-packages/pandas/core/indexing.py:357: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/Users/ianbolliger/anaconda/envs/cooking_people/lib/python3.6/site-packages/pandas/core/indexing.py:537: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "# load dataframes \n",
    "dfs_bus = load_vals_bus(s)\n",
    "timing_df_bus = get_timing_df_bus(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indoor temp/rh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ianbolliger/anaconda/envs/cooking_people/lib/python3.6/site-packages/pandas/core/computation/expressions.py:179: UserWarning: evaluating in Python space because the '+' operator is not supported by numexpr for the bool dtype, use '|' instead\n",
      "  .format(op=op_str, alt_op=unsupported[op_str]))\n"
     ]
    }
   ],
   "source": [
    "out_df_bus = calc_session_level_indoor_vals(dfs_bus['indoor'], timing_df_bus, s.bus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outdoor temp/rh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df_bus = add_outdoor_vals(out_df_bus, dfs_bus['outdoor'], timing_df_bus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df_bus.to_csv(save_fpath_bus,float_format='%.2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
