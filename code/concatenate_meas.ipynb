{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create session-level measurements\n",
    "\n",
    "This notebook concatenates all of the measurements collected on various dates into one csv per site. The metrics consist of the following measures, with one summary statistic per session-treatment group:\n",
    "\n",
    "- indoor air temperature (mean, std dev, quartiles)\n",
    "- indoor relative humidity (mean, std dev, quartiles)\n",
    "- outdoor air temperature, avg/min/max over the date of each session.\n",
    "- outdoor relative humidity, avg/min/max over the date of each session.\n",
    "- participant level mean T and RH, averaged over duration of session.\n",
    "- operative temp in control and tx\n",
    "- CO2 in control and tx\n",
    "\n",
    "This also aggregates the module timing data and saves it in a separate file.\n",
    "\n",
    "These files are used for plotting in the separate `publication_figures_and_tables.ipynb` notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "home_dir = \"/Users/ianbolliger/Dropbox/Temperature & Behavior/Experiments\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pdb\n",
    "import pickle\n",
    "import sys\n",
    "from datetime import timedelta\n",
    "from glob import glob\n",
    "from os.path import basename\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from utilities import *\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set()\n",
    "sns.set_context(\"talk\")\n",
    "\n",
    "idx = pd.IndexSlice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = Settings(home_dir)\n",
    "home_dir = Path(home_dir)\n",
    "\n",
    "save_fpath_berk = Path(s.berk.home_dir) / \"session_level_environmental_data.csv\"\n",
    "save_fpath_bus = Path(s.bus.home_dir) / \"session_level_environmental_data.csv\"\n",
    "\n",
    "int_data_dir = Path(\"../data/int\")\n",
    "\n",
    "sites = [\"Nairobi\", \"California\"]\n",
    "txs = [\"control\", \"treatment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_session_level_indoor_vals(dfs, timing_df, site_settings):\n",
    "    out_df = pd.DataFrame()\n",
    "    idx = pd.IndexSlice\n",
    "\n",
    "    for grp_ix, grp in enumerate([\"control\", \"treatment\"]):\n",
    "        grp_df = timing_df[timing_df[\"Treatment group\"] == grp_ix]\n",
    "\n",
    "        # one dataframe for each sensor location\n",
    "        loc_dfs = []\n",
    "        for loc in (\n",
    "            site_settings.sens_locs + [str(i) for i in range(1, 7)] + [\"Top\", \"co2\"]\n",
    "        ):\n",
    "            tmp_df = dfs[grp][loc].reset_index()\n",
    "            tmp_df[\"sess\"] = pd.cut(tmp_df[\"time\"], bins=grp_df.index)\n",
    "            grouped = tmp_df.groupby(\"sess\").describe()\n",
    "\n",
    "            # drop pilot sessions where we don't have room-level sensors (only individual)\n",
    "            grouped = grouped[grouped.loc[:, idx[:, \"count\"]].sum(axis=1) != 0]\n",
    "\n",
    "            # don't need # of measurements taken in session\n",
    "            grouped = grouped.drop(columns=\"count\", level=1)\n",
    "\n",
    "            loc_dfs.append(grouped)\n",
    "\n",
    "        # estimate average values for sessions where only one sensor recording\n",
    "        # then average the sensors for each session\n",
    "        room_sesh_vals = average_two_sensors(loc_dfs)\n",
    "\n",
    "        # clarify that these are indoor temps and RH vals\n",
    "        def renamer(x):\n",
    "            if x == \"one_sensor_only\":\n",
    "                return \"one_sensor_only_in\"\n",
    "            return x.split(\"_\")[0] + \"_in_\" + x.split(\"_\")[1]\n",
    "\n",
    "        sesh_vals = room_sesh_vals.rename(renamer, axis=1)\n",
    "\n",
    "        ## add participant-level sensors\n",
    "        for s_ix in range(1, 7):\n",
    "            this_df = loc_dfs[s_ix + 1]\n",
    "\n",
    "            # convert to single-level index\n",
    "            this_df.columns = [\n",
    "                (j[0] + \"_p{}_\".format(s_ix) + j[1]).rstrip(\"_\")\n",
    "                for j in this_df.columns.values\n",
    "            ]\n",
    "\n",
    "            # join onto sesh_vals dataframes\n",
    "            sesh_vals = sesh_vals.join(this_df, how=\"outer\")\n",
    "\n",
    "        ## add operative temp\n",
    "        this_df = loc_dfs[8]\n",
    "        this_df.columns = [\n",
    "            (j[0] + \"_\" + j[1]).rstrip(\"_\") for j in this_df.columns.values\n",
    "        ]\n",
    "        sesh_vals = sesh_vals.join(this_df, how=\"outer\")\n",
    "\n",
    "        ## add CO2\n",
    "        this_df = loc_dfs[9]\n",
    "        this_df.columns = [\n",
    "            (j[0] + \"_\" + j[1]).rstrip(\"_\") for j in this_df.columns.values\n",
    "        ]\n",
    "        sesh_vals = sesh_vals.join(this_df, how=\"outer\")\n",
    "\n",
    "        ## join onto treatment group / session # data\n",
    "        sesh_vals = sesh_vals.join(grp_df, how=\"inner\")\n",
    "        out_df = out_df.append(sesh_vals)\n",
    "\n",
    "    # format nicely\n",
    "    out_df = out_df.rename(\n",
    "        columns={\n",
    "            \"Date\": \"date\",\n",
    "            \"Session in day\": \"session\",\n",
    "            \"Treatment group\": \"treatment\",\n",
    "        }\n",
    "    )\n",
    "    out_df = out_df.set_index([\"date\", \"session\", \"treatment\"])\n",
    "    out_df = out_df.drop(columns=[\"start_time\", \"end_time\"])\n",
    "    out_df.columns = [c.rstrip(\"%\") for c in out_df.columns]\n",
    "    out_df = out_df.sort_index()\n",
    "    out_df = out_df[out_df.notnull().any(axis=1)]\n",
    "\n",
    "    return out_df\n",
    "\n",
    "\n",
    "def average_two_sensors(loc_dfs):\n",
    "    loc_dfs = bias_correct_one_sensor(loc_dfs)\n",
    "    n_other_sensors = len(loc_dfs) - 2\n",
    "    sesh_vals = (loc_dfs[0] + loc_dfs[1]) / 2\n",
    "    sesh_vals[\"one_sensor_only\"] = pd.DataFrame(\n",
    "        [loc_dfs[0][\"one_sensor_only\"], loc_dfs[1][\"one_sensor_only\"]]\n",
    "    ).max()\n",
    "    return sesh_vals\n",
    "\n",
    "\n",
    "def bias_correct_one_sensor(loc_dfs):\n",
    "    \"\"\"When only one sensor in a room, bias correct that sensor to estimate\n",
    "    the average of the two sensors for that session.\"\"\"\n",
    "    # find mean difference in sensor\n",
    "    mean_diff = (loc_dfs[1] - loc_dfs[0]).mean()\n",
    "    # flatten index\n",
    "    mean_diff.index = [(i[0] + \"_\" + i[1]).rstrip(\"_\") for i in mean_diff.index.values]\n",
    "\n",
    "    # get df with all sessions where at least one sensor was working\n",
    "    all_locs = loc_dfs[1].join(loc_dfs[0], rsuffix=\"0\", lsuffix=\"1\")\n",
    "\n",
    "    # adjust for one-sensor-only times\n",
    "    # workaround b/c reindex fails with intervalIndex (bug)\n",
    "    for i in [0, 1]:\n",
    "        loc_dfs[i] = all_locs.loc[\n",
    "            :, idx[[k for k in all_locs.columns.levels[0] if k[-1] == str(i)], :]\n",
    "        ]\n",
    "\n",
    "        # convert to single-level index\n",
    "        loc_dfs[i] = loc_dfs[i].rename(lambda x: x[:-1], axis=1, level=0)\n",
    "        loc_dfs[i].columns = [\n",
    "            (j[0] + \"_\" + j[1]).rstrip(\"_\") for j in loc_dfs[i].columns.values\n",
    "        ]\n",
    "\n",
    "        # mark where we did bias correction\n",
    "        loc_dfs[i][\"one_sensor_only\"] = loc_dfs[i].isnull().any(axis=1)\n",
    "\n",
    "    loc_dfs[1].iloc[:, :-1] = (\n",
    "        loc_dfs[1]\n",
    "        .iloc[:, :-1]\n",
    "        .where(~loc_dfs[1][\"one_sensor_only\"], loc_dfs[0].iloc[:, :-1] + mean_diff)\n",
    "    )\n",
    "    loc_dfs[0].iloc[:, :-1] = (\n",
    "        loc_dfs[0]\n",
    "        .iloc[:, :-1]\n",
    "        .where(~loc_dfs[0][\"one_sensor_only\"], loc_dfs[1].iloc[:, :-1] - mean_diff)\n",
    "    )\n",
    "\n",
    "    return loc_dfs\n",
    "\n",
    "\n",
    "def add_outdoor_vals(output_df, dfs_outdoor, timing_df):\n",
    "    res = output_df.copy()\n",
    "    for i in [\"min\", \"mean\", \"max\"]:\n",
    "        to_join = dfs_outdoor[i].copy()\n",
    "        to_join.index = pd.to_datetime(to_join.index)\n",
    "        to_join = (\n",
    "            timing_df.join(to_join, on=\"Date\", how=\"inner\")\n",
    "            .drop_duplicates()\n",
    "            .set_index([\"Date\", \"Session in day\", \"Treatment group\"])\n",
    "            .loc[:, [\"T\", \"RH\"]]\n",
    "        )\n",
    "        to_join.columns = [r + \"_out_daily\" + i for r in to_join.columns]\n",
    "        to_join.index.names = res.index.names\n",
    "        res = res.join(to_join, how=\"outer\")\n",
    "    return res\n",
    "\n",
    "\n",
    "def get_timeseries_by_sesion(temp_dfs, timing_df, site_settings):\n",
    "    \"\"\"Return df where rows are 5-min time intervals from start of session and columns are sessions.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Berkeley"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ianbolliger/miniconda3/envs/temp-behavior-env/lib/python3.8/site-packages/pandas/core/indexing.py:845: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/Users/ianbolliger/miniconda3/envs/temp-behavior-env/lib/python3.8/site-packages/pandas/core/indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "# load timing data\n",
    "timing_df_berk = get_timing_df_berk(s)\n",
    "\n",
    "# load all raw data\n",
    "dfs_berk = load_vals_berkeley(s)\n",
    "\n",
    "# save aggregated raw data for future loading\n",
    "int_data_dir.mkdir(parents=True, exist_ok=True)\n",
    "with open(join(int_data_dir, \"sensor_data_berk.pickle\"), \"wb\") as f:\n",
    "    pickle.dump(dfs_berk, f)\n",
    "\n",
    "# get session-level aggregate statistics\n",
    "out_df_berk = calc_session_level_indoor_vals(dfs_berk[\"indoor\"], timing_df_berk, s.berk)\n",
    "out_df_berk = add_outdoor_vals(out_df_berk, dfs_berk[\"outdoor\"], timing_df_berk)\n",
    "\n",
    "# save aggregate data\n",
    "out_df_berk.to_csv(save_fpath_berk, float_format=\"%.2f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Busara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ianbolliger/miniconda3/envs/temp-behavior-env/lib/python3.8/site-packages/pandas/core/indexing.py:845: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/Users/ianbolliger/miniconda3/envs/temp-behavior-env/lib/python3.8/site-packages/pandas/core/indexing.py:966: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "# load timing dataframe\n",
    "timing_df_bus = get_timing_df_bus(s)\n",
    "\n",
    "# load values dataframe\n",
    "dfs_bus = load_vals_bus(s)\n",
    "\n",
    "# save raw data for future loading\n",
    "with open(join(int_data_dir, \"sensor_data_bus.pickle\"), \"wb\") as f:\n",
    "    pickle.dump(dfs_bus, f)\n",
    "\n",
    "# get session-level aggregate statistics\n",
    "out_df_bus = calc_session_level_indoor_vals(dfs_bus[\"indoor\"], timing_df_bus, s.bus)\n",
    "out_df_bus = add_outdoor_vals(out_df_bus, dfs_bus[\"outdoor\"], timing_df_bus)\n",
    "\n",
    "# save aggregate data\n",
    "out_df_bus.to_csv(save_fpath_bus, float_format=\"%.2f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module Timing Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get dataframes of T timeseries by session\n",
    "\n",
    "ts_dfs = {}\n",
    "\n",
    "in_dfs = {\"California\": dfs_berk[\"indoor\"], \"Nairobi\": dfs_bus[\"indoor\"]}\n",
    "timing_dfs = {\"California\": timing_df_berk, \"Nairobi\": timing_df_bus}\n",
    "site_settings = {\"California\": s.berk, \"Nairobi\": s.bus}\n",
    "for site in sites:\n",
    "    ts_dfs[site] = {}\n",
    "    timing_df = timing_dfs[site]\n",
    "\n",
    "    for grp_ix, grp in enumerate([\"control\", \"treatment\"]):\n",
    "        grp_df = timing_df[timing_df[\"Treatment group\"] == grp_ix]\n",
    "        ts_dfs[site][grp] = {}\n",
    "\n",
    "        # one dataframe for each sensor location\n",
    "        loc_dfs = []\n",
    "        for loc in (\n",
    "            site_settings[site].sens_locs\n",
    "            + [str(i) for i in range(1, 7)]\n",
    "            + [\"Top\", \"co2\"]\n",
    "        ):\n",
    "            tmp_df = in_dfs[site][grp][loc].reset_index()\n",
    "\n",
    "            # assign to session\n",
    "            tmp_df[\"sess\"] = pd.cut(tmp_df[\"time\"], bins=grp_df.index)\n",
    "\n",
    "            # keep only measurements during sessions\n",
    "            tmp_df = tmp_df[tmp_df[\"sess\"].notnull()]\n",
    "\n",
    "            # get interval for each observation\n",
    "            tmp_df[\"t_ix_sess\"] = tmp_df.groupby(\"sess\").cumcount()\n",
    "\n",
    "            # adjust for when we had 5 min intervals in berkeley\n",
    "            if loc in site_settings[site].sens_locs:\n",
    "                tmp_df[\"t_ix_sess\"] = tmp_df[\"t_ix_sess\"].where(\n",
    "                    tmp_df[\"time\"] >= s.berk.sensor_swap_date, tmp_df[\"t_ix_sess\"] * 5\n",
    "                )\n",
    "\n",
    "            # pivot to wide table\n",
    "            if loc == \"Top\":\n",
    "                this_val = [\"Top\"]\n",
    "            elif loc == \"co2\":\n",
    "                this_val = [\"co2\"]\n",
    "            else:\n",
    "                this_val = [\"T\", \"RH\"]\n",
    "            for t in this_val:\n",
    "                val_by_sess = tmp_df.pivot(\n",
    "                    index=\"sess\", columns=\"t_ix_sess\", values=t\n",
    "                ).T\n",
    "                loc_dfs.append(val_by_sess)\n",
    "\n",
    "        # ignoring small # of sessions where only one sensor was in room\n",
    "        combined_cols = set(loc_dfs[0].columns).intersection(set(loc_dfs[2].columns))\n",
    "        mean_df = (\n",
    "            loc_dfs[0].loc[:, combined_cols] + loc_dfs[2].loc[:, combined_cols]\n",
    "        ) / 2\n",
    "        ts_dfs[site][grp][\"room_avg_T\"] = mean_df\n",
    "        mean_df_RH = (\n",
    "            loc_dfs[1].loc[:, combined_cols] + loc_dfs[3].loc[:, combined_cols]\n",
    "        ) / 2\n",
    "        ts_dfs[site][grp][\"room_avg_RH\"] = mean_df_RH\n",
    "        for i in range(1, 7):\n",
    "            ts_dfs[site][grp][\"p{}_T\".format(i)] = loc_dfs[2 * (i + 1)]\n",
    "            ts_dfs[site][grp][\"p{}_RH\".format(i)] = loc_dfs[2 * (i + 1) + 1]\n",
    "        ts_dfs[site][grp][\"T_op\"] = loc_dfs[16]\n",
    "        ts_dfs[site][grp][\"CO2\"] = loc_dfs[17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No module time data: <utilities.Settings object at 0x7fd307117550>\n"
     ]
    }
   ],
   "source": [
    "modules = [\n",
    "    \"production\",\n",
    "    \"dictator\",\n",
    "    \"risk_game\",\n",
    "    \"t_preference\",\n",
    "    \"trust\",\n",
    "    \"public_goods\",\n",
    "    \"ravens\",\n",
    "    \"joy_O_D\",\n",
    "    \"survey\",\n",
    "    \"charity\",\n",
    "]\n",
    "loc_dirs = {\n",
    "    \"California\": join(home_dir, \"Xlab data\", \"Main experiment data\", \"Modules\"),\n",
    "    \"Nairobi\": join(home_dir, \"Busara data\", \"Main experiment data\", \"Modules\"),\n",
    "}\n",
    "\n",
    "tzs = {\"California\": \"US/Pacific\", \"Nairobi\": \"Africa/Nairobi\"}\n",
    "\n",
    "\n",
    "def ts_parser(d, tz):\n",
    "    return (\n",
    "        pd.to_datetime(d, unit=\"s\").tz_localize(\"UTC\").tz_convert(tz).tz_localize(None)\n",
    "    )\n",
    "\n",
    "\n",
    "def get_mean_temp(row, temps_df, st_time, loc, tx):\n",
    "    st = int((row[\"start_time\"] - st_time).total_seconds() / 60)\n",
    "    end = int((row[\"end_time\"] - st_time).total_seconds() / 60)\n",
    "\n",
    "    if st < 0:\n",
    "        ## There are many cases in Nairobi where the start time for production\n",
    "        ## module occurs before the recorded starting time in the experiment_timing.csv\n",
    "        ## file. IB is investigating this w/ Ray but the hunch is that the Busara team\n",
    "        ## opened the experiment to the introduction page prior to participants entering room.\n",
    "        ## This is b/c the time spent on the intro page is often very long. So we are assuming\n",
    "        ## the start times are 0 for these cases.\n",
    "        st = 0\n",
    "    return pd.Series([temps_df[st:end].mean(), st, end], index=[\"temps\", \"st\", \"end\"])\n",
    "\n",
    "\n",
    "module_temps = {\n",
    "    \"California\": {\n",
    "        \"control\": pd.DataFrame(index=modules),\n",
    "        \"treatment\": pd.DataFrame(index=modules),\n",
    "    },\n",
    "    \"Nairobi\": {\n",
    "        \"control\": pd.DataFrame(index=modules),\n",
    "        \"treatment\": pd.DataFrame(index=modules),\n",
    "    },\n",
    "}\n",
    "start_times = {\n",
    "    \"California\": {\n",
    "        \"control\": pd.DataFrame(index=modules),\n",
    "        \"treatment\": pd.DataFrame(index=modules),\n",
    "    },\n",
    "    \"Nairobi\": {\n",
    "        \"control\": pd.DataFrame(index=modules),\n",
    "        \"treatment\": pd.DataFrame(index=modules),\n",
    "    },\n",
    "}\n",
    "end_times = {\n",
    "    \"California\": {\n",
    "        \"control\": pd.DataFrame(index=modules),\n",
    "        \"treatment\": pd.DataFrame(index=modules),\n",
    "    },\n",
    "    \"Nairobi\": {\n",
    "        \"control\": pd.DataFrame(index=modules),\n",
    "        \"treatment\": pd.DataFrame(index=modules),\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "for loc in sites:\n",
    "    date_dirs = glob(join(loc_dirs[loc], \"*\"))\n",
    "    for d in date_dirs:\n",
    "        sessions = glob(join(d, \"*\"))\n",
    "        for se in sessions:\n",
    "            sess = basename(se).split()\n",
    "            if sess[2] == \"C\":\n",
    "                tx = \"control\"\n",
    "            elif sess[2] == \"T\":\n",
    "                tx = \"treatment\"\n",
    "            else:\n",
    "                raise ValueError\n",
    "\n",
    "            ts_fpath = glob(join(se, \"TimeSpent*\"))\n",
    "            if len(ts_fpath):\n",
    "                ts_fpath = ts_fpath[0]\n",
    "            else:\n",
    "                print(\"No module time data: {}\".format(se))\n",
    "                continue\n",
    "            this_df = pd.read_csv(\n",
    "                ts_fpath,\n",
    "                parse_dates=[\"time_stamp\"],\n",
    "                date_parser=lambda x: ts_parser(x, tzs[loc]),\n",
    "            )\n",
    "            this_df = this_df.loc[\n",
    "                this_df[\"app_name\"].isin(modules),\n",
    "                [\n",
    "                    \"app_name\",\n",
    "                    \"participant__id_in_session\",\n",
    "                    \"time_stamp\",\n",
    "                    \"seconds_on_page\",\n",
    "                ],\n",
    "            ]\n",
    "            this_df = this_df.sort_values([\"participant__id_in_session\", \"app_name\"])\n",
    "            midtime = this_df.sort_values(\"time_stamp\").iloc[\n",
    "                int(this_df.shape[0] / 2), 2\n",
    "            ]\n",
    "            groups = this_df.groupby([\"participant__id_in_session\", \"app_name\"])\n",
    "\n",
    "            # start times\n",
    "            st = groups.first()\n",
    "            # For production, take starting point as \"end of intro slide\"\n",
    "            # b/c this comes first and in busara they navigated to this page\n",
    "            # before the participants entered\n",
    "            page_start = st[\"time_stamp\"] - st[\"seconds_on_page\"].apply(\n",
    "                lambda x: timedelta(seconds=x)\n",
    "            )\n",
    "            st = page_start.where(\n",
    "                st.index.get_level_values(1) != \"production\", st[\"time_stamp\"]\n",
    "            )\n",
    "            st.name = \"start_time\"\n",
    "\n",
    "            # end times\n",
    "            end = groups.last()[\"time_stamp\"]\n",
    "            end.name = \"end_time\"\n",
    "\n",
    "            # get times for temp data\n",
    "            try:\n",
    "                this_temps = ts_dfs[loc][tx][\"room_avg_T\"][midtime].interpolate()\n",
    "                sess_st_time = this_temps.name.left\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "            this_times = pd.DataFrame([st, end]).T\n",
    "            vals = this_times.apply(\n",
    "                lambda x: get_mean_temp(x, this_temps, sess_st_time, loc, tx), axis=1\n",
    "            )\n",
    "            vals = vals[vals[\"temps\"].notnull()]\n",
    "\n",
    "            # average accross participants\n",
    "            vals = vals.groupby(level=1).median()\n",
    "            module_temps[loc][tx][this_temps.name] = vals[\"temps\"]\n",
    "            start_times[loc][tx][this_temps.name] = vals[\"st\"]\n",
    "            end_times[loc][tx][this_temps.name] = vals[\"end\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ianbolliger/miniconda3/envs/temp-behavior-env/lib/python3.8/site-packages/IPython/core/interactiveshell.py:2857: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  result = self._run_cell(\n"
     ]
    }
   ],
   "source": [
    "idx = pd.IndexSlice\n",
    "ix = pd.MultiIndex.from_product(\n",
    "    [sites, txs, modules], names=[\"location\", \"group\", \"module\"]\n",
    ")\n",
    "t_mod_df = pd.DataFrame(index=ix, columns=[\"st_time\", \"end_time\", \"mean_temp\"])\n",
    "for loc in sites:\n",
    "    for tx in txs:\n",
    "        this_df = pd.DataFrame(\n",
    "            {\n",
    "                \"st_time\": start_times[loc][tx].median(axis=1),\n",
    "                \"end_time\": end_times[loc][tx].median(axis=1),\n",
    "                \"mean_temp\": module_temps[loc][tx].median(axis=1),\n",
    "            }\n",
    "        )\n",
    "        this_df.index = pd.MultiIndex.from_product(\n",
    "            [[loc], [tx], list(start_times[loc][tx].index)],\n",
    "            names=[\"location\", \"group\", \"module\"],\n",
    "        )\n",
    "        t_mod_df.loc[idx[loc, tx, :], :] = this_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_mod_df.to_csv(home_dir / \"Analysis\" / \"Tables\" / \"module_level_temps.csv\")\n",
    "t_mod_df.to_csv(Path(int_data_dir) / \"module_level_temps.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:temp-behavior-env]",
   "language": "python",
   "name": "conda-env-temp-behavior-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
